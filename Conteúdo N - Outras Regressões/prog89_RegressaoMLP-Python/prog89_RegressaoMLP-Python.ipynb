{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão - Redes Neurais (MLP)\n",
    "#### Aplicando o multi layer perceptron em um problema de regressão e não linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca pandas do python\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando os dados no 'dataframe'\n",
    "dataframe = pd.read_csv('house_prices.csv', encoding = 'utf-8', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando as variáveis x e y\n",
    "x = dataframe.iloc[:, 3:19].values\n",
    "y = dataframe.iloc[:, 2:3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca sklearn do python\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando os objetos 'x_scaler' e 'y_scaler'\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalonando as variáveis x e y\n",
    "x = x_scaler.fit_transform(x)\n",
    "y = y_scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca sklearn do python\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados em modelo de treinando e modelo de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca sklearn do python\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando e configurando o regressor\n",
    "regressor = MLPRegressor(hidden_layer_sizes = (9, 9), verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alysson\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.41356082\n",
      "Iteration 2, loss = 0.24663984\n",
      "Iteration 3, loss = 0.18632285\n",
      "Iteration 4, loss = 0.16123178\n",
      "Iteration 5, loss = 0.14788916\n",
      "Iteration 6, loss = 0.13968585\n",
      "Iteration 7, loss = 0.13378673\n",
      "Iteration 8, loss = 0.12873729\n",
      "Iteration 9, loss = 0.12516456\n",
      "Iteration 10, loss = 0.12184553\n",
      "Iteration 11, loss = 0.11934194\n",
      "Iteration 12, loss = 0.11666504\n",
      "Iteration 13, loss = 0.11431819\n",
      "Iteration 14, loss = 0.11193386\n",
      "Iteration 15, loss = 0.10960345\n",
      "Iteration 16, loss = 0.10697807\n",
      "Iteration 17, loss = 0.10466347\n",
      "Iteration 18, loss = 0.10222577\n",
      "Iteration 19, loss = 0.09982447\n",
      "Iteration 20, loss = 0.09732285\n",
      "Iteration 21, loss = 0.09496318\n",
      "Iteration 22, loss = 0.09314628\n",
      "Iteration 23, loss = 0.09109457\n",
      "Iteration 24, loss = 0.08980645\n",
      "Iteration 25, loss = 0.08764451\n",
      "Iteration 26, loss = 0.08618615\n",
      "Iteration 27, loss = 0.08529923\n",
      "Iteration 28, loss = 0.08388520\n",
      "Iteration 29, loss = 0.08313684\n",
      "Iteration 30, loss = 0.08167567\n",
      "Iteration 31, loss = 0.08076758\n",
      "Iteration 32, loss = 0.07969499\n",
      "Iteration 33, loss = 0.07927344\n",
      "Iteration 34, loss = 0.07828699\n",
      "Iteration 35, loss = 0.07762825\n",
      "Iteration 36, loss = 0.07689584\n",
      "Iteration 37, loss = 0.07632284\n",
      "Iteration 38, loss = 0.07609783\n",
      "Iteration 39, loss = 0.07526851\n",
      "Iteration 40, loss = 0.07486561\n",
      "Iteration 41, loss = 0.07459101\n",
      "Iteration 42, loss = 0.07402296\n",
      "Iteration 43, loss = 0.07351887\n",
      "Iteration 44, loss = 0.07352325\n",
      "Iteration 45, loss = 0.07293995\n",
      "Iteration 46, loss = 0.07261180\n",
      "Iteration 47, loss = 0.07238447\n",
      "Iteration 48, loss = 0.07260548\n",
      "Iteration 49, loss = 0.07213938\n",
      "Iteration 50, loss = 0.07178420\n",
      "Iteration 51, loss = 0.07114976\n",
      "Iteration 52, loss = 0.07139363\n",
      "Iteration 53, loss = 0.07123114\n",
      "Iteration 54, loss = 0.07098037\n",
      "Iteration 55, loss = 0.07047353\n",
      "Iteration 56, loss = 0.07043529\n",
      "Iteration 57, loss = 0.07040389\n",
      "Iteration 58, loss = 0.06985399\n",
      "Iteration 59, loss = 0.07025215\n",
      "Iteration 60, loss = 0.06977416\n",
      "Iteration 61, loss = 0.06924577\n",
      "Iteration 62, loss = 0.06968807\n",
      "Iteration 63, loss = 0.06886240\n",
      "Iteration 64, loss = 0.06866089\n",
      "Iteration 65, loss = 0.06854668\n",
      "Iteration 66, loss = 0.06820130\n",
      "Iteration 67, loss = 0.06793118\n",
      "Iteration 68, loss = 0.06802387\n",
      "Iteration 69, loss = 0.06774554\n",
      "Iteration 70, loss = 0.06761489\n",
      "Iteration 71, loss = 0.06711830\n",
      "Iteration 72, loss = 0.06687500\n",
      "Iteration 73, loss = 0.06702861\n",
      "Iteration 74, loss = 0.06662915\n",
      "Iteration 75, loss = 0.06653723\n",
      "Iteration 76, loss = 0.06652501\n",
      "Iteration 77, loss = 0.06589990\n",
      "Iteration 78, loss = 0.06615692\n",
      "Iteration 79, loss = 0.06609321\n",
      "Iteration 80, loss = 0.06541362\n",
      "Iteration 81, loss = 0.06525074\n",
      "Iteration 82, loss = 0.06565729\n",
      "Iteration 83, loss = 0.06532867\n",
      "Iteration 84, loss = 0.06504453\n",
      "Iteration 85, loss = 0.06481656\n",
      "Iteration 86, loss = 0.06507521\n",
      "Iteration 87, loss = 0.06460266\n",
      "Iteration 88, loss = 0.06518821\n",
      "Iteration 89, loss = 0.06433283\n",
      "Iteration 90, loss = 0.06409342\n",
      "Iteration 91, loss = 0.06414198\n",
      "Iteration 92, loss = 0.06403185\n",
      "Iteration 93, loss = 0.06389109\n",
      "Iteration 94, loss = 0.06373365\n",
      "Iteration 95, loss = 0.06373251\n",
      "Iteration 96, loss = 0.06380328\n",
      "Iteration 97, loss = 0.06363093\n",
      "Iteration 98, loss = 0.06379918\n",
      "Iteration 99, loss = 0.06344621\n",
      "Iteration 100, loss = 0.06341506\n",
      "Iteration 101, loss = 0.06338271\n",
      "Iteration 102, loss = 0.06344331\n",
      "Iteration 103, loss = 0.06348983\n",
      "Iteration 104, loss = 0.06300500\n",
      "Iteration 105, loss = 0.06294300\n",
      "Iteration 106, loss = 0.06283949\n",
      "Iteration 107, loss = 0.06262474\n",
      "Iteration 108, loss = 0.06250507\n",
      "Iteration 109, loss = 0.06258777\n",
      "Iteration 110, loss = 0.06278134\n",
      "Iteration 111, loss = 0.06236974\n",
      "Iteration 112, loss = 0.06244004\n",
      "Iteration 113, loss = 0.06234203\n",
      "Iteration 114, loss = 0.06235034\n",
      "Iteration 115, loss = 0.06235590\n",
      "Iteration 116, loss = 0.06216991\n",
      "Iteration 117, loss = 0.06230188\n",
      "Iteration 118, loss = 0.06236882\n",
      "Iteration 119, loss = 0.06200082\n",
      "Iteration 120, loss = 0.06159300\n",
      "Iteration 121, loss = 0.06225046\n",
      "Iteration 122, loss = 0.06171761\n",
      "Iteration 123, loss = 0.06193236\n",
      "Iteration 124, loss = 0.06139991\n",
      "Iteration 125, loss = 0.06121360\n",
      "Iteration 126, loss = 0.06163983\n",
      "Iteration 127, loss = 0.06180173\n",
      "Iteration 128, loss = 0.06134640\n",
      "Iteration 129, loss = 0.06129497\n",
      "Iteration 130, loss = 0.06122248\n",
      "Iteration 131, loss = 0.06144292\n",
      "Iteration 132, loss = 0.06146714\n",
      "Iteration 133, loss = 0.06135574\n",
      "Iteration 134, loss = 0.06151483\n",
      "Iteration 135, loss = 0.06112485\n",
      "Iteration 136, loss = 0.06103652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(9, 9), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treinando o regressor\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8792882891528244\n"
     ]
    }
   ],
   "source": [
    "# observando a porcentagem de adaptação do algoritmo em relação aos dados de treinamento\n",
    "score = regressor.score(x_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8704551079602627"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observando a porcentagem de adaptação do algoritmo em relação aos dados de teste\n",
    "regressor.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição do Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo as previsões do algoritmo para a base de dados de teste\n",
    "previsoes = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reeescalonando os dados para observar o erro médio absoluto\n",
    "y_test = y_scaler.inverse_transform(y_test)\n",
    "previsoes = y_scaler.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro Médio Absoluto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca sklearn do python\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77855.30824376903\n"
     ]
    }
   ],
   "source": [
    "# observando o erro absoluto médio\n",
    "mae = mean_absolute_error(y_test, previsoes)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alguma Dúvida? Entre em Contato Comigo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Me envie um e-mail](mailto:alysson.barbosa@ee.ufcg.edu.br);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
